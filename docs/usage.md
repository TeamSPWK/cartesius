# Usage

After installing the package, you can use the package to access the datasets and train your own model.

## Data

### Train data

The train dataset is generated **randomly**.

Each sample of the dataset is a **randomly generated polygon**, with an **arbitrary position**, **arbitrary scale**, etc...

For each polygon, labels are generated, and the model is trained to predict these labels.

Each task has a different label.

### Validation & Test data

The test dataset is a list of **handcrafted** polygons.

Similarly to the train dataset, labels are generated for each polygon and the models are evaluated on their predictions of those labels.

!!! check "Info"
    The test set is trying to cover as many different cases of polygons as possible, including types of polygon that can't be generated by the train dataset, in order to assess the generalization capabilities of the models.

!!! important
    It's very possible that the test set is not complete. It's still a work in progress, feel free to propose some changes !

The validation dataset is exactly like the test dataset, but with different (arbitrary) position, orientation, scale, etc...

!!! danger "Advanced"
    You can find the script used to generate the polygons in the [Generating handcrafted polygons for test/validation](gen_handcraft_poly.md) page.

## Tasks

Models are trained and evaluated on several tasks. The goal is to get good representation of the input polygon, good enough to properly predict the labels of all tasks.

List of tasks currently implemented :

* **`area`** : Predict the area of the polygon.
* **`perimeter`** : Predict the perimeter of the polygon.
* **`size`** : Predict the width and the height of the polygon.
* **`convexity`** : Predict the "convexity" of the polygon. Convexity is defined as the area of the polygon divided by the area of its convex hull. It represents "how much convex a polygon is".
* **`min_clear`** : Predict the minimum clearance of the polygon. The minimum clearance is the smallest distance by which a node should be moved to produce an invalid geometry.
* **`centroid`** : Predict the x and y coordinates of the centroid of the polygon.
* **`ombr_ratio`** : Predict "oriented minimum bounding rectangle ratio" of the polygon. OMBR ratio is defined as the area of the polygon divided by the area of its oriented minimum bounding rectangle. It represents "how close the polygon is to a rectangle".
* **`aspect_ratio`** : Predict "oriented minimum bounding rectangle aspect ratio" of the polygon. OMBR aspect ratio is defined as the length of shorter line divided by longer line of the OMBR. It represents wideness of the polygon.
* **`opening_ratio`** : Predict "opening ratio" of the polygon. Opening ratio is defined as the area of the opening applied polygon divided by the area of the original polygon. It represents "how much polygon have useful space that is wide enough".

## Leaderboard

You can see the [public leaderboard on Kaggle](https://www.kaggle.com/c/cartesius/leaderboard).

## Notebooks

A baseline notebook in included in the folder `notebooks/`.

In this notebook, we implement a basic Transformer model, and train it using `cartesius` dataset.

At the end of the notebook, the model is evaluated, and a file `submission.csv` is saved. You can use this file for submission to the [Kaggle competition](https://www.kaggle.com/c/cartesius/).
